---
version: v3.0
status: complete
date: 2026-01-15
source: architecture-v3.0.md, prd-v3.0.md
---

# Epics & Stories - AI-as-Me v3.0

## Epic 1: è¿›åŒ–å¼•æ“æ ¸å¿ƒ (P0)

**ç›®æ ‡ï¼š** å®ç°å®Œæ•´çš„ experience â†’ pattern â†’ rule è¿›åŒ–é—­ç¯

### Story 1.1: Experience Collector
**ä¼˜å…ˆçº§ï¼š** P0  
**é¢„ä¼°ï¼š** 4h  
**ä¾èµ–ï¼š** æ— 

**ä»»åŠ¡åˆ†è§£ï¼š**
1. å®šä¹‰ `Experience` æ•°æ®ç±»ï¼ˆ0.5hï¼‰
2. å®ç° `collect()` æ–¹æ³•ï¼ˆ2hï¼‰
3. å®ç° `get_recent()` æ–¹æ³•ï¼ˆ1hï¼‰
4. å•å…ƒæµ‹è¯•ï¼ˆ0.5hï¼‰

**éªŒæ”¶æ ‡å‡†ï¼š**
- [ ] `Experience` æ•°æ®ç±»å®šä¹‰
- [ ] ä»»åŠ¡å®Œæˆåè‡ªåŠ¨æ”¶é›†ç»éªŒ
- [ ] ç»éªŒä¿å­˜åˆ° `experience/successes/` æˆ– `experience/failures/`
- [ ] ç»éªŒç´¢å¼•åˆ°å‘é‡å­˜å‚¨ï¼ˆå¤ç”¨ RAGï¼‰
- [ ] æµ‹è¯•è¦†ç›–ç‡ >80%

**å®ç°ä»£ç ï¼š**
```python
# src/ai_as_me/evolution/collector.py
from dataclasses import dataclass, asdict
from datetime import datetime
from pathlib import Path
import json

@dataclass
class Experience:
    task_id: str
    description: str
    tool_used: str
    result: str
    success: bool
    duration: float
    timestamp: datetime
    
    def to_dict(self):
        d = asdict(self)
        d['timestamp'] = self.timestamp.isoformat()
        return d

class ExperienceCollector:
    def __init__(self, experience_dir: Path, vector_store):
        self.experience_dir = experience_dir
        self.vector_store = vector_store
        self.successes_dir = experience_dir / "successes"
        self.failures_dir = experience_dir / "failures"
        self.successes_dir.mkdir(parents=True, exist_ok=True)
        self.failures_dir.mkdir(parents=True, exist_ok=True)
    
    def collect(self, task, result: str, success: bool, duration: float = 0) -> Experience:
        exp = Experience(
            task_id=task.id,
            description=task.description,
            tool_used=getattr(task, 'tool', 'unknown'),
            result=result[:500],  # æˆªæ–­
            success=success,
            duration=duration,
            timestamp=datetime.now()
        )
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        target_dir = self.successes_dir if success else self.failures_dir
        file_path = target_dir / f"{exp.task_id}.json"
        file_path.write_text(json.dumps(exp.to_dict(), indent=2))
        
        # ç´¢å¼•åˆ°å‘é‡å­˜å‚¨
        from ai_as_me.rag.retriever import TaskExperience
        rag_exp = TaskExperience(
            task_id=exp.task_id,
            description=exp.description,
            tool_used=exp.tool_used,
            result_summary=exp.result,
            success=exp.success,
            user_feedback=None,
            created_at=exp.timestamp
        )
        self.vector_store.add(rag_exp)
        
        return exp
    
    def get_recent(self, limit: int = 10) -> list[Experience]:
        all_files = sorted(
            list(self.successes_dir.glob("*.json")) + 
            list(self.failures_dir.glob("*.json")),
            key=lambda p: p.stat().st_mtime,
            reverse=True
        )
        
        experiences = []
        for f in all_files[:limit]:
            data = json.loads(f.read_text())
            data['timestamp'] = datetime.fromisoformat(data['timestamp'])
            experiences.append(Experience(**data))
        
        return experiences
```

**æµ‹è¯•ç”¨ä¾‹ï¼š**
```python
# tests/unit/test_experience_collector.py
def test_collect_success():
    collector = ExperienceCollector(tmp_path, mock_vector_store)
    exp = collector.collect(task, "result", success=True)
    assert exp.success
    assert (tmp_path / "successes" / f"{task.id}.json").exists()

def test_get_recent():
    experiences = collector.get_recent(limit=5)
    assert len(experiences) <= 5
```

---

### Story 1.2: Pattern Recognizer
**ä¼˜å…ˆçº§ï¼š** P0  
**é¢„ä¼°ï¼š** 6h  
**ä¾èµ–ï¼š** Story 1.1

**ä»»åŠ¡åˆ†è§£ï¼š**
1. å®šä¹‰ `Pattern` æ•°æ®ç±»ï¼ˆ0.5hï¼‰
2. å®ç° LLM prompt æ„å»ºï¼ˆ1hï¼‰
3. å®ç°æ¨¡å¼è¯†åˆ«é€»è¾‘ï¼ˆ3hï¼‰
4. å®ç°ç½®ä¿¡åº¦è¯„ä¼°ï¼ˆ1hï¼‰
5. å•å…ƒæµ‹è¯•ï¼ˆ0.5hï¼‰

**éªŒæ”¶æ ‡å‡†ï¼š**
- [ ] `Pattern` æ•°æ®ç±»å®šä¹‰
- [ ] ä»è¿‘æœŸç»éªŒä¸­è¯†åˆ«æ¨¡å¼ï¼ˆLLM è¾…åŠ©ï¼‰
- [ ] æ¨¡å¼ç½®ä¿¡åº¦è¯„ä¼° >0.6
- [ ] æ¨¡å¼ä¿å­˜åˆ° `experience/patterns/`
- [ ] æµ‹è¯•è¦†ç›–ç‡ >80%

**å®ç°ä»£ç ï¼š**
```python
# src/ai_as_me/evolution/recognizer.py
from dataclasses import dataclass
from pathlib import Path
import json

@dataclass
class Pattern:
    pattern_id: str
    description: str
    frequency: int
    source_tasks: list[str]
    confidence: float
    category: str
    
    def to_dict(self):
        return {
            "pattern_id": self.pattern_id,
            "description": self.description,
            "frequency": self.frequency,
            "source_tasks": self.source_tasks,
            "confidence": self.confidence,
            "category": self.category
        }

class PatternRecognizer:
    def __init__(self, llm_client, experience_dir: Path):
        self.llm = llm_client
        self.patterns_dir = experience_dir / "patterns"
        self.patterns_dir.mkdir(parents=True, exist_ok=True)
    
    def recognize(self, experiences: list) -> list[Pattern]:
        if len(experiences) < 3:
            return []  # ç»éªŒå¤ªå°‘ï¼Œæ— æ³•è¯†åˆ«æ¨¡å¼
        
        prompt = self._build_prompt(experiences)
        response = self.llm.chat([
            {"role": "system", "content": "ä½ æ˜¯æ¨¡å¼è¯†åˆ«ä¸“å®¶ï¼Œä»ä»»åŠ¡æ‰§è¡Œå†å²ä¸­æå–å¯å¤ç”¨æ¨¡å¼ã€‚"},
            {"role": "user", "content": prompt}
        ])
        
        patterns = self._parse_patterns(response, experiences)
        
        # ä¿å­˜æ¨¡å¼
        for p in patterns:
            file_path = self.patterns_dir / f"{p.pattern_id}.json"
            file_path.write_text(json.dumps(p.to_dict(), indent=2))
        
        return patterns
    
    def _build_prompt(self, experiences: list) -> str:
        exp_summaries = []
        for i, exp in enumerate(experiences, 1):
            status = "âœ“" if exp.success else "âœ—"
            exp_summaries.append(
                f"{i}. [{status}] {exp.description[:100]} (å·¥å…·: {exp.tool_used})"
            )
        
        return f"""åˆ†æä»¥ä¸‹ {len(experiences)} ä¸ªä»»åŠ¡æ‰§è¡Œè®°å½•ï¼Œè¯†åˆ«å¯å¤ç”¨çš„æ¨¡å¼ï¼š

{chr(10).join(exp_summaries)}

è¯·è¯†åˆ« 1-2 ä¸ªæ¨¡å¼ï¼Œæ¯ä¸ªæ¨¡å¼åŒ…å«ï¼š
1. æ¨¡å¼æè¿°ï¼ˆç®€æ´æ˜ç¡®ï¼‰
2. é€‚ç”¨åœºæ™¯
3. å»ºè®®çš„å¤„ç†æ–¹å¼
4. ç½®ä¿¡åº¦ï¼ˆ0.0-1.0ï¼‰

æ ¼å¼ï¼š
[ç±»åˆ«] æ¨¡å¼æè¿° | ç½®ä¿¡åº¦: X.X
é€‚ç”¨åœºæ™¯: ...
å»ºè®®: ..."""
    
    def _parse_patterns(self, response: str, experiences: list) -> list[Pattern]:
        patterns = []
        lines = response.strip().split('\n')
        
        current_pattern = None
        for line in lines:
            line = line.strip()
            if line.startswith('['):
                # è§£ææ¨¡å¼å¤´
                import re
                match = re.match(r'\[([^\]]+)\]\s*(.+?)\s*\|\s*ç½®ä¿¡åº¦:\s*([\d.]+)', line)
                if match:
                    category = match.group(1)
                    description = match.group(2)
                    confidence = float(match.group(3))
                    
                    if confidence >= 0.6:  # ç½®ä¿¡åº¦é˜ˆå€¼
                        pattern_id = f"pattern-{len(patterns)+1}"
                        current_pattern = Pattern(
                            pattern_id=pattern_id,
                            description=description,
                            frequency=len(experiences),
                            source_tasks=[e.task_id for e in experiences],
                            confidence=confidence,
                            category=category
                        )
                        patterns.append(current_pattern)
        
        return patterns
```

---

### Story 1.3: Rule Generator
**ä¼˜å…ˆçº§ï¼š** P0  
**é¢„ä¼°ï¼š** 4h  
**ä¾èµ–ï¼š** Story 1.2

**ä»»åŠ¡åˆ†è§£ï¼š**
1. å®šä¹‰ `GeneratedRule` æ•°æ®ç±»ï¼ˆ0.5hï¼‰
2. å®ç°è§„åˆ™ç”Ÿæˆ promptï¼ˆ1hï¼‰
3. å®ç°è§„åˆ™ç”Ÿæˆé€»è¾‘ï¼ˆ2hï¼‰
4. å•å…ƒæµ‹è¯•ï¼ˆ0.5hï¼‰

**éªŒæ”¶æ ‡å‡†ï¼š**
- [ ] `GeneratedRule` æ•°æ®ç±»å®šä¹‰
- [ ] ä»æ¨¡å¼ç”Ÿæˆè§„åˆ™ï¼ˆLLM è¾…åŠ©ï¼‰
- [ ] è§„åˆ™æ ¼å¼åŒ–ä¸º Markdown
- [ ] ç½®ä¿¡åº¦é˜ˆå€¼è¿‡æ»¤ï¼ˆ<0.6 ä¸ç”Ÿæˆï¼‰
- [ ] æµ‹è¯•è¦†ç›–ç‡ >80%

**å®ç°ä»£ç ï¼š**
```python
# src/ai_as_me/evolution/generator.py
from dataclasses import dataclass
from datetime import datetime

@dataclass
class GeneratedRule:
    rule_id: str
    category: str
    content: str
    source_pattern: str
    confidence: float
    created_at: datetime
    metadata: dict
    
    def to_markdown(self) -> str:
        return f"""---
source: {self.source_pattern}
created: {self.created_at.strftime('%Y-%m-%d')}
confidence: {self.confidence}
applied_count: 0
---

# {self.category} è§„åˆ™

## è§„åˆ™å†…å®¹

{self.content}

## æ¥æº

ä»æ¨¡å¼ {self.source_pattern} æå–ã€‚

## å…ƒæ•°æ®

- ç½®ä¿¡åº¦: {self.confidence}
- åˆ›å»ºæ—¶é—´: {self.created_at.isoformat()}
"""

class RuleGenerator:
    def __init__(self, llm_client):
        self.llm = llm_client
    
    def generate(self, pattern) -> GeneratedRule | None:
        if pattern.confidence < 0.6:
            return None
        
        prompt = self._build_prompt(pattern)
        response = self.llm.chat([
            {"role": "system", "content": "ä½ æ˜¯è§„åˆ™ç”Ÿæˆä¸“å®¶ï¼Œå°†æ¨¡å¼è½¬åŒ–ä¸ºå¯æ‰§è¡Œçš„å†³ç­–è§„åˆ™ã€‚"},
            {"role": "user", "content": prompt}
        ])
        
        return self._parse_rule(response, pattern)
    
    def _build_prompt(self, pattern) -> str:
        return f"""åŸºäºä»¥ä¸‹æ¨¡å¼ç”Ÿæˆä¸€æ¡å†³ç­–è§„åˆ™ï¼š

æ¨¡å¼ç±»åˆ«: {pattern.category}
æ¨¡å¼æè¿°: {pattern.description}
ç½®ä¿¡åº¦: {pattern.confidence}

ç”Ÿæˆè§„åˆ™è¦æ±‚ï¼š
1. æ˜ç¡®çš„è§¦å‘æ¡ä»¶
2. å…·ä½“çš„è¡ŒåŠ¨å»ºè®®
3. ç®€æ´æ¸…æ™°ï¼ˆ1-2 å¥è¯ï¼‰

æ ¼å¼ï¼š
å½“ [è§¦å‘æ¡ä»¶] æ—¶ï¼Œ[è¡ŒåŠ¨å»ºè®®]ã€‚"""
    
    def _parse_rule(self, response: str, pattern) -> GeneratedRule:
        rule_id = f"rule-{datetime.now().strftime('%Y%m%d%H%M%S')}"
        
        return GeneratedRule(
            rule_id=rule_id,
            category=pattern.category,
            content=response.strip(),
            source_pattern=pattern.pattern_id,
            confidence=pattern.confidence,
            created_at=datetime.now(),
            metadata={
                "source_tasks": pattern.source_tasks,
                "frequency": pattern.frequency
            }
        )
```

---

### Story 1.4: Soul Writer
**ä¼˜å…ˆçº§ï¼š** P0  
**é¢„ä¼°ï¼š** 2h  
**ä¾èµ–ï¼š** Story 2.1 (Soul ç›®å½•é‡æ„)

**ä»»åŠ¡åˆ†è§£ï¼š**
1. å®ç° `write_rule()` æ–¹æ³•ï¼ˆ1hï¼‰
2. å®ç°è§„åˆ™æ ¼å¼åŒ–ï¼ˆ0.5hï¼‰
3. å•å…ƒæµ‹è¯•ï¼ˆ0.5hï¼‰

**éªŒæ”¶æ ‡å‡†ï¼š**
- [ ] åˆ›å»º `soul/rules/learned/` ç›®å½•
- [ ] è§„åˆ™å†™å…¥ä¸ºç‹¬ç«‹ Markdown æ–‡ä»¶
- [ ] æ–‡ä»¶å‘½åï¼š`{category}-{timestamp}.md`
- [ ] åŒ…å«å…ƒæ•°æ®ï¼ˆsource, confidence, createdï¼‰
- [ ] æµ‹è¯•è¦†ç›–ç‡ >80%

**å®ç°ä»£ç ï¼š**
```python
# src/ai_as_me/evolution/writer.py
from pathlib import Path

class SoulWriter:
    def __init__(self, soul_dir: Path):
        self.learned_dir = soul_dir / "rules" / "learned"
        self.learned_dir.mkdir(parents=True, exist_ok=True)
    
    def write_rule(self, rule) -> Path:
        filename = f"{rule.category}-{rule.rule_id}.md"
        path = self.learned_dir / filename
        
        content = rule.to_markdown()
        path.write_text(content)
        
        return path
    
    def list_rules(self) -> list[Path]:
        return sorted(self.learned_dir.glob("*.md"))
    
    def count_rules(self) -> int:
        return len(self.list_rules())
```

---

### Story 1.5: Evolution Engine é›†æˆ
**ä¼˜å…ˆçº§ï¼š** P0  
**é¢„ä¼°ï¼š** 4h  
**ä¾èµ–ï¼š** Story 1.1-1.4

**ä»»åŠ¡åˆ†è§£ï¼š**
1. å®ç° `EvolutionEngine` ä¸»ç±»ï¼ˆ2hï¼‰
2. é›†æˆåˆ° `Agent._process_task()`ï¼ˆ1hï¼‰
3. é›†æˆæµ‹è¯•ï¼ˆ1hï¼‰

**éªŒæ”¶æ ‡å‡†ï¼š**
- [ ] `EvolutionEngine` ä¸»ç±»å®ç°
- [ ] ç¼–æ’å®Œæ•´è¿›åŒ–æµç¨‹
- [ ] é›†æˆåˆ° `Agent._process_task()`
- [ ] æ¯ä»»åŠ¡å®Œæˆåè‡ªåŠ¨è§¦å‘
- [ ] ç«¯åˆ°ç«¯æµ‹è¯•é€šè¿‡

**å®ç°ä»£ç ï¼š**
```python
# src/ai_as_me/evolution/engine.py
from pathlib import Path

class EvolutionEngine:
    def __init__(self, config: dict):
        self.collector = ExperienceCollector(
            Path(config['experience_dir']),
            config['vector_store']
        )
        self.recognizer = PatternRecognizer(
            config['llm_client'],
            Path(config['experience_dir'])
        )
        self.generator = RuleGenerator(config['llm_client'])
        self.writer = SoulWriter(Path(config['soul_dir']))
    
    def evolve(self, task, result: str, success: bool, duration: float = 0) -> dict:
        # 1. æ”¶é›†ç»éªŒ
        exp = self.collector.collect(task, result, success, duration)
        
        # 2. è·å–è¿‘æœŸç»éªŒ
        recent = self.collector.get_recent(limit=10)
        
        # 3. è¯†åˆ«æ¨¡å¼
        patterns = self.recognizer.recognize(recent)
        
        # 4. ç”Ÿæˆè§„åˆ™
        rules = []
        for p in patterns:
            rule = self.generator.generate(p)
            if rule:
                path = self.writer.write_rule(rule)
                rules.append({"rule": rule, "path": path})
        
        return {
            "experience": exp,
            "patterns": patterns,
            "rules": rules
        }
```

**Agent é›†æˆï¼š**
```python
# src/ai_as_me/core/agent.py ä¿®æ”¹
def _process_task(self, task_path: Path):
    # ... ç°æœ‰æ‰§è¡Œé€»è¾‘ ...
    
    if success and self.evolution_engine:
        # è§¦å‘è¿›åŒ–
        start_time = time.time()
        evolution_result = self.evolution_engine.evolve(
            task, result, success=True, duration=time.time() - start_time
        )
        
        if evolution_result["rules"]:
            print(f"  ğŸ§¬ è¿›åŒ–: ç”Ÿæˆ {len(evolution_result['rules'])} æ¡æ–°è§„åˆ™")
            for r in evolution_result["rules"]:
                print(f"     - [{r['rule'].category}] {r['rule'].content[:50]}...")
```

---

## Epic 2: Soul ç³»ç»Ÿæ‰©å±• (P0)

**ç›®æ ‡ï¼š** æ”¯æŒ rules/ ç›®å½•ç»“æ„å’Œ learned/ è§„åˆ™åŠ è½½

### Story 2.1: Soul ç›®å½•é‡æ„
**ä¼˜å…ˆçº§ï¼š** P0  
**é¢„ä¼°ï¼š** 2h  
**ä¾èµ–ï¼š** æ— 

**ä»»åŠ¡åˆ†è§£ï¼š**
1. åˆ›å»ºç›®å½•ç»“æ„ï¼ˆ0.5hï¼‰
2. ç¼–å†™è¿ç§»è„šæœ¬ï¼ˆ1hï¼‰
3. æµ‹è¯•è¿ç§»ï¼ˆ0.5hï¼‰

**éªŒæ”¶æ ‡å‡†ï¼š**
- [ ] åˆ›å»º `soul/rules/core/` ç›®å½•
- [ ] åˆ›å»º `soul/rules/learned/` ç›®å½•
- [ ] è¿ç§»è„šæœ¬ï¼š`rules.md` â†’ `rules/core/base.md`
- [ ] ä¿ç•™ `rules.md` ä½œä¸ºå¤‡ä»½

**å®ç°ä»£ç ï¼š**
```python
# src/ai_as_me/soul/migrator.py
from pathlib import Path
import shutil

class SoulMigrator:
    def __init__(self, soul_dir: Path):
        self.soul_dir = soul_dir
        self.old_rules = soul_dir / "rules.md"
        self.rules_dir = soul_dir / "rules"
        self.core_dir = self.rules_dir / "core"
        self.learned_dir = self.rules_dir / "learned"
    
    def migrate(self):
        # åˆ›å»ºç›®å½•
        self.core_dir.mkdir(parents=True, exist_ok=True)
        self.learned_dir.mkdir(parents=True, exist_ok=True)
        
        # è¿ç§» rules.md
        if self.old_rules.exists():
            # å¤‡ä»½
            backup = self.soul_dir / "rules.md.backup"
            shutil.copy(self.old_rules, backup)
            
            # è¿ç§»åˆ° core/base.md
            new_path = self.core_dir / "base.md"
            shutil.move(self.old_rules, new_path)
            
            print(f"âœ“ è¿ç§»å®Œæˆ: rules.md â†’ rules/core/base.md")
            print(f"âœ“ å¤‡ä»½ä¿å­˜: rules.md.backup")
        
        # åˆ›å»º .gitkeep
        (self.learned_dir / ".gitkeep").touch()
```

**CLI å‘½ä»¤ï¼š**
```python
# src/ai_as_me/cli_main.py æ·»åŠ 
@cli.command()
def migrate_soul():
    """è¿ç§» Soul ç›®å½•åˆ° v3.0 ç»“æ„"""
    from ai_as_me.soul.migrator import SoulMigrator
    migrator = SoulMigrator(Path("soul"))
    migrator.migrate()
```

---

### Story 2.2: SoulLoader æ‰©å±•
**ä¼˜å…ˆçº§ï¼š** P0  
**é¢„ä¼°ï¼š** 2h  
**ä¾èµ–ï¼š** Story 2.1

**ä»»åŠ¡åˆ†è§£ï¼š**
1. å®ç° `load_all_rules()` æ–¹æ³•ï¼ˆ1hï¼‰
2. å…¼å®¹æ—§ç»“æ„ï¼ˆ0.5hï¼‰
3. å•å…ƒæµ‹è¯•ï¼ˆ0.5hï¼‰

**éªŒæ”¶æ ‡å‡†ï¼š**
- [ ] `load_all_rules()` åŠ è½½ core + learned
- [ ] å…¼å®¹æ—§ `rules.md` ç»“æ„
- [ ] é¦–æ¬¡è¿è¡Œè‡ªåŠ¨è¿ç§»
- [ ] æµ‹è¯•è¦†ç›–ç‡ >80%

**å®ç°ä»£ç ï¼š**
```python
# src/ai_as_me/soul/loader.py æ‰©å±•
class SoulLoader:
    def __init__(self, soul_dir: Path):
        # ... ç°æœ‰ä»£ç  ...
        self.rules_dir = soul_dir / "rules"
        self.core_rules_dir = self.rules_dir / "core"
        self.learned_rules_dir = self.rules_dir / "learned"
        self.old_rules_file = soul_dir / "rules.md"
    
    def load_all_rules(self) -> str:
        """åŠ è½½æ‰€æœ‰è§„åˆ™ï¼ˆcore + learnedï¼‰"""
        # æ£€æŸ¥æ˜¯å¦éœ€è¦è¿ç§»
        if self.old_rules_file.exists() and not self.rules_dir.exists():
            from ai_as_me.soul.migrator import SoulMigrator
            migrator = SoulMigrator(self.soul_dir)
            migrator.migrate()
        
        rules = []
        
        # åŠ è½½ core è§„åˆ™
        if self.core_rules_dir.exists():
            for f in sorted(self.core_rules_dir.glob("*.md")):
                rules.append(f"## Core Rule: {f.stem}\n{f.read_text()}")
        
        # åŠ è½½ learned è§„åˆ™
        if self.learned_rules_dir.exists():
            for f in sorted(self.learned_rules_dir.glob("*.md")):
                rules.append(f"## Learned Rule: {f.stem}\n{f.read_text()}")
        
        return "\n\n".join(rules) if rules else "# No rules defined"
    
    def load_all(self) -> str:
        """åŠ è½½å®Œæ•´ Soul ä¸Šä¸‹æ–‡"""
        parts = []
        
        if self.profile_file.exists():
            parts.append(f"# Profile\n{self.profile_file.read_text()}")
        
        parts.append(f"# Rules\n{self.load_all_rules()}")
        
        if self.mission_file.exists():
            parts.append(f"# Mission\n{self.mission_file.read_text()}")
        
        return "\n\n".join(parts)
```

---

## Epic 3: Experience ç›®å½• (P1)

**ç›®æ ‡ï¼š** ç»“æ„åŒ–å­˜å‚¨æ‰§è¡Œç»éªŒ

### Story 3.1: Experience ç›®å½•ç»“æ„
**ä¼˜å…ˆçº§ï¼š** P1  
**é¢„ä¼°ï¼š** 1h  
**ä¾èµ–ï¼š** æ— 

**ä»»åŠ¡åˆ†è§£ï¼š**
1. åˆ›å»ºç›®å½•ç»“æ„ï¼ˆ0.5hï¼‰
2. æ·»åŠ  READMEï¼ˆ0.5hï¼‰

**éªŒæ”¶æ ‡å‡†ï¼š**
- [ ] åˆ›å»º `experience/successes/`
- [ ] åˆ›å»º `experience/failures/`
- [ ] åˆ›å»º `experience/patterns/`
- [ ] `.gitkeep` æ–‡ä»¶
- [ ] README.md è¯´æ˜

**å®ç°ï¼š**
```bash
mkdir -p experience/{successes,failures,patterns}
touch experience/{successes,failures,patterns}/.gitkeep
```

```markdown
# experience/README.md
# Experience ç›®å½•

å­˜å‚¨ä»»åŠ¡æ‰§è¡Œç»éªŒå’Œè¯†åˆ«çš„æ¨¡å¼ã€‚

## ç›®å½•ç»“æ„

- `successes/` - æˆåŠŸæ‰§è¡Œçš„ä»»åŠ¡ç»éªŒ
- `failures/` - å¤±è´¥çš„ä»»åŠ¡ç»éªŒ
- `patterns/` - è¯†åˆ«å‡ºçš„å¯å¤ç”¨æ¨¡å¼

## æ–‡ä»¶æ ¼å¼

æ‰€æœ‰æ–‡ä»¶ä½¿ç”¨ JSON æ ¼å¼ï¼Œæ–‡ä»¶åä¸º `{task_id}.json`ã€‚
```

---

### Story 3.2: Experience æ–‡ä»¶æ ¼å¼
**ä¼˜å…ˆçº§ï¼š** P1  
**é¢„ä¼°ï¼š** 1h  
**ä¾èµ–ï¼š** Story 3.1

**éªŒæ”¶æ ‡å‡†ï¼š**
- [ ] JSON æ ¼å¼å®šä¹‰
- [ ] åŒ…å«ï¼štask_id, description, tool, result, success, timestamp
- [ ] æ–‡ä»¶å‘½åï¼š`{task_id}.json`
- [ ] Schema æ–‡æ¡£

**æ ¼å¼å®šä¹‰ï¼š**
```json
{
  "task_id": "task-20260115-001",
  "description": "å®ç° Experience Collector",
  "tool_used": "claude_code",
  "result": "æˆåŠŸå®ç°ï¼Œæµ‹è¯•é€šè¿‡",
  "success": true,
  "duration": 3600.5,
  "timestamp": "2026-01-15T19:00:00+08:00"
}
```

---

## Epic 4: Skills æ¶æ„ (P1)

**ç›®æ ‡ï¼š** å®ç° Skills è°ƒç”¨æœºåˆ¶

### Story 4.1: SKILL.md æ ¼å¼å®šä¹‰
**ä¼˜å…ˆçº§ï¼š** P1  
**é¢„ä¼°ï¼š** 1h  
**ä¾èµ–ï¼š** æ— 

**éªŒæ”¶æ ‡å‡†ï¼š**
- [ ] YAML frontmatter å®šä¹‰ï¼ˆname, triggersï¼‰
- [ ] èƒ½åŠ›æè¿°éƒ¨åˆ†
- [ ] è°ƒç”¨æ–¹å¼è¯´æ˜
- [ ] æ ¼å¼æ–‡æ¡£

**æ ¼å¼å®šä¹‰ï¼š**
```markdown
# skills/SKILL_FORMAT.md
---
name: skill_name
triggers:
  - task_type: architecture
  - task_type: planning
  - capability_gap: true
version: 1.0
---

# Skill Name

## èƒ½åŠ›æè¿°

æè¿°è¿™ä¸ª Skill æä¾›çš„èƒ½åŠ›ã€‚

## è§¦å‘æ¡ä»¶

- ä»»åŠ¡ç±»å‹ä¸º architecture æˆ– planning
- æ£€æµ‹åˆ°èƒ½åŠ›ç¼ºå£æ—¶

## è°ƒç”¨æ–¹å¼

è¯´æ˜å¦‚ä½•è°ƒç”¨è¿™ä¸ª Skillã€‚
```

---

### Story 4.2: BMad Skill åˆ›å»º
**ä¼˜å…ˆçº§ï¼š** P1  
**é¢„ä¼°ï¼š** 2h  
**ä¾èµ–ï¼š** Story 4.1

**éªŒæ”¶æ ‡å‡†ï¼š**
- [ ] åˆ›å»º `skills/bmad/SKILL.md`
- [ ] å®šä¹‰è§¦å‘æ¡ä»¶ï¼ˆarchitecture, planning, capability_gapï¼‰
- [ ] å…³è” `_bmad/` ç›®å½•
- [ ] ä½¿ç”¨è¯´æ˜

**å®ç°ï¼š**
```markdown
# skills/bmad/SKILL.md
---
name: bmad
triggers:
  - task_type: architecture
  - task_type: planning
  - capability_gap: true
version: 1.0
---

# BMad Method Skill

## èƒ½åŠ›æè¿°

BMad Method æä¾›å®Œæ•´çš„è½¯ä»¶å¼€å‘æ–¹æ³•è®ºæ”¯æŒï¼ŒåŒ…æ‹¬ï¼š
- äº§å“åˆ†æï¼ˆProduct Briefï¼‰
- éœ€æ±‚è§„åˆ’ï¼ˆPRDï¼‰
- æ¶æ„è®¾è®¡ï¼ˆArchitectureï¼‰
- ä»»åŠ¡åˆ†è§£ï¼ˆEpics & Storiesï¼‰

## è§¦å‘æ¡ä»¶

1. ä»»åŠ¡ç±»å‹ä¸º architecture æˆ– planning
2. æ£€æµ‹åˆ°èƒ½åŠ›ç¼ºå£ï¼ˆç°æœ‰å·¥å…·æ— æ³•å¤„ç†ï¼‰

## è°ƒç”¨æ–¹å¼

åŠ è½½ `_bmad/` ç›®å½•ä¸‹çš„ç›¸å…³å·¥ä½œæµï¼š
- `_bmad/bmm/workflows/1-analysis/` - äº§å“åˆ†æ
- `_bmad/bmm/workflows/2-plan-workflows/` - éœ€æ±‚è§„åˆ’
- `_bmad/bmm/workflows/3-solutioning/` - æ¶æ„è®¾è®¡
```

---

### Story 4.3: SkillLoader å®ç°
**ä¼˜å…ˆçº§ï¼š** P1  
**é¢„ä¼°ï¼š** 3h  
**ä¾èµ–ï¼š** Story 4.1, 4.2

**ä»»åŠ¡åˆ†è§£ï¼š**
1. å®ç° `SkillLoader` ç±»ï¼ˆ1.5hï¼‰
2. é›†æˆåˆ° `SkillMatcher`ï¼ˆ1hï¼‰
3. å•å…ƒæµ‹è¯•ï¼ˆ0.5hï¼‰

**éªŒæ”¶æ ‡å‡†ï¼š**
- [ ] åŠ è½½ SKILL.md æ–‡ä»¶
- [ ] è§£æè§¦å‘æ¡ä»¶
- [ ] `should_invoke()` åˆ¤æ–­é€»è¾‘
- [ ] é›†æˆåˆ° SkillMatcher
- [ ] æµ‹è¯•è¦†ç›–ç‡ >80%

**å®ç°ä»£ç ï¼š**
```python
# src/ai_as_me/skills/loader.py
from dataclasses import dataclass
from pathlib import Path
import yaml

@dataclass
class Skill:
    name: str
    triggers: list[dict]
    description: str
    invoke_path: str

class SkillLoader:
    def __init__(self, skills_dir: Path):
        self.skills_dir = skills_dir
    
    def load_skill(self, name: str) -> Skill | None:
        skill_file = self.skills_dir / name / "SKILL.md"
        if not skill_file.exists():
            return None
        
        content = skill_file.read_text()
        
        # è§£æ YAML frontmatter
        if content.startswith('---'):
            parts = content.split('---', 2)
            frontmatter = yaml.safe_load(parts[1])
            description = parts[2].strip()
            
            return Skill(
                name=frontmatter['name'],
                triggers=frontmatter.get('triggers', []),
                description=description,
                invoke_path=str(skill_file.parent)
            )
        
        return None
    
    def should_invoke(self, skill: Skill, task, capability_gap: bool = False) -> bool:
        for trigger in skill.triggers:
            if 'task_type' in trigger:
                if hasattr(task, 'type') and task.type == trigger['task_type']:
                    return True
            if 'capability_gap' in trigger and trigger['capability_gap']:
                if capability_gap:
                    return True
        return False
```

**é›†æˆåˆ° SkillMatcherï¼š**
```python
# src/ai_as_me/orchestrator/skill_matcher.py æ‰©å±•
class SkillMatcher:
    def __init__(self, config_path: Path, db_path: str):
        # ... ç°æœ‰ä»£ç  ...
        self.skill_loader = SkillLoader(Path("skills"))
    
    def match_with_skills(self, task_description: str):
        # 1. å°è¯•å¸¸è§„å·¥å…·åŒ¹é…
        tool = self.match(task_description)
        
        # 2. æ£€æµ‹èƒ½åŠ›ç¼ºå£
        gap = self.detect_capability_gap(task_description)
        
        # 3. å¦‚æœæœ‰ç¼ºå£ï¼Œå°è¯• Skills
        if gap:
            bmad_skill = self.skill_loader.load_skill("bmad")
            if bmad_skill and self.skill_loader.should_invoke(bmad_skill, task, gap):
                return {"tool": tool, "skill": "bmad", "capability_gap": True}
        
        return {"tool": tool, "skill": None, "capability_gap": False}
```

---

## Epic 5: è¿›åŒ–æ—¥å¿— (P1)

**ç›®æ ‡ï¼š** è®°å½•å’Œè¿½è¸ªè¿›åŒ–è¿‡ç¨‹

### Story 5.1: Evolution Logger
**ä¼˜å…ˆçº§ï¼š** P1  
**é¢„ä¼°ï¼š** 2h  
**ä¾èµ–ï¼š** Epic 1

**ä»»åŠ¡åˆ†è§£ï¼š**
1. å®ç° `EvolutionLogger` ç±»ï¼ˆ1hï¼‰
2. é›†æˆåˆ° `EvolutionEngine`ï¼ˆ0.5hï¼‰
3. å•å…ƒæµ‹è¯•ï¼ˆ0.5hï¼‰

**éªŒæ”¶æ ‡å‡†ï¼š**
- [ ] åˆ›å»º `logs/evolution.jsonl`
- [ ] è®°å½•ï¼štimestamp, task_id, patterns_found, rules_generated
- [ ] JSON Lines æ ¼å¼
- [ ] æµ‹è¯•è¦†ç›–ç‡ >80%

**å®ç°ä»£ç ï¼š**
```python
# src/ai_as_me/evolution/logger.py
from pathlib import Path
import json
from datetime import datetime

class EvolutionLogger:
    def __init__(self, log_path: Path):
        self.log_path = log_path
        self.log_path.parent.mkdir(parents=True, exist_ok=True)
    
    def log(self, exp, patterns: list, rules: list):
        entry = {
            "timestamp": datetime.now().isoformat(),
            "task_id": exp.task_id,
            "experience_recorded": True,
            "patterns_found": len(patterns),
            "rules_generated": len(rules),
            "rule_ids": [r.rule_id for r in rules],
            "rule_categories": [r.category for r in rules]
        }
        
        with open(self.log_path, "a") as f:
            f.write(json.dumps(entry) + "\n")
    
    def get_stats(self, days: int = 7) -> dict:
        """è·å–æœ€è¿‘ N å¤©çš„ç»Ÿè®¡"""
        from datetime import timedelta
        cutoff = datetime.now() - timedelta(days=days)
        
        total_rules = 0
        total_patterns = 0
        
        if not self.log_path.exists():
            return {"total_rules": 0, "total_patterns": 0}
        
        with open(self.log_path) as f:
            for line in f:
                entry = json.loads(line)
                entry_time = datetime.fromisoformat(entry['timestamp'])
                if entry_time >= cutoff:
                    total_rules += entry['rules_generated']
                    total_patterns += entry['patterns_found']
        
        return {
            "total_rules": total_rules,
            "total_patterns": total_patterns,
            "days": days
        }
```

---

### Story 5.2: è¿›åŒ–ç»Ÿè®¡ CLI
**ä¼˜å…ˆçº§ï¼š** P2  
**é¢„ä¼°ï¼š** 2h  
**ä¾èµ–ï¼š** Story 5.1

**éªŒæ”¶æ ‡å‡†ï¼š**
- [ ] `ai-as-me evolve stats` å‘½ä»¤
- [ ] æ˜¾ç¤ºï¼šæ€»è§„åˆ™æ•°ã€æœ¬å‘¨æ–°å¢ã€åº”ç”¨æ¬¡æ•°
- [ ] æ ¼å¼åŒ–è¾“å‡º

**å®ç°ä»£ç ï¼š**
```python
# src/ai_as_me/cli_main.py æ·»åŠ 
@cli.group()
def evolve():
    """è¿›åŒ–ç›¸å…³å‘½ä»¤"""
    pass

@evolve.command()
@click.option('--days', default=7, help='ç»Ÿè®¡å¤©æ•°')
def stats(days):
    """æ˜¾ç¤ºè¿›åŒ–ç»Ÿè®¡"""
    from ai_as_me.evolution.logger import EvolutionLogger
    logger = EvolutionLogger(Path("logs/evolution.jsonl"))
    stats = logger.get_stats(days)
    
    click.echo(f"ğŸ“Š è¿›åŒ–ç»Ÿè®¡ï¼ˆæœ€è¿‘ {days} å¤©ï¼‰")
    click.echo(f"  è§„åˆ™ç”Ÿæˆ: {stats['total_rules']} æ¡")
    click.echo(f"  æ¨¡å¼è¯†åˆ«: {stats['total_patterns']} ä¸ª")
```

---

## Epic 6: OpenCode é›†æˆ (P1)

**ç›®æ ‡ï¼š** å®Œå–„ MVP å·¥å…·æ ˆ

### Story 6.1: OpenCode é…ç½®
**ä¼˜å…ˆçº§ï¼š** P1  
**é¢„ä¼°ï¼š** 2h  
**ä¾èµ–ï¼š** æ— 

**ä»»åŠ¡åˆ†è§£ï¼š**
1. åˆ›å»º `.opencode/config.yaml`ï¼ˆ1hï¼‰
2. å®šä¹‰è‡ªå®šä¹‰å‘½ä»¤ï¼ˆ0.5hï¼‰
3. æµ‹è¯•éªŒè¯ï¼ˆ0.5hï¼‰

**éªŒæ”¶æ ‡å‡†ï¼š**
- [ ] åˆ›å»º `.opencode/config.yaml`
- [ ] å®šä¹‰ default agentï¼ˆåŠ è½½ Soulï¼‰
- [ ] è‡ªå®šä¹‰å‘½ä»¤ï¼šsoul-check, evolve
- [ ] é…ç½®éªŒè¯é€šè¿‡

**å®ç°ï¼š**
```yaml
# .opencode/config.yaml
version: 1
project:
  name: AI-as-Me
  type: python
  description: è‡ªè¿›åŒ– AI æ•°å­—åˆ†èº«ç³»ç»Ÿ

agents:
  default:
    system_prompt: |
      ä½ æ˜¯ AI-as-Meï¼Œä¸€ä¸ªèƒ½è‡ªæˆ‘è¿›åŒ–çš„ AI ä»£ç†ã€‚
      
      ä½ çš„ Soulï¼ˆçµé­‚ï¼‰åŒ…å«ï¼š
      - Profile: soul/profile.md
      - Mission: soul/mission.md
      - Core Rules: soul/rules/core/*.md
      - Learned Rules: soul/rules/learned/*.md
      
      ä½ ä¼šä»æ¯æ¬¡ä»»åŠ¡æ‰§è¡Œä¸­å­¦ä¹ ï¼Œè‡ªåŠ¨ç”Ÿæˆæ–°è§„åˆ™åˆ° learned/ ç›®å½•ã€‚

commands:
  soul-check:
    description: æ£€æŸ¥ Soul çŠ¶æ€
    script: |
      python -m ai_as_me.cli soul status
  
  evolve:
    description: æ‰‹åŠ¨è§¦å‘è¿›åŒ–åæ€
    script: |
      python -m ai_as_me.cli evolve --force
  
  stats:
    description: æŸ¥çœ‹è¿›åŒ–ç»Ÿè®¡
    script: |
      python -m ai_as_me.cli evolve stats
```

```markdown
# .opencode/agents/default.md
# AI-as-Me Default Agent

åŠ è½½å®Œæ•´ Soul ä¸Šä¸‹æ–‡ï¼ŒåŒ…æ‹¬ï¼š
- Profileï¼ˆä¸ªäººæ¡£æ¡ˆï¼‰
- Missionï¼ˆä½¿å‘½ç›®æ ‡ï¼‰
- Core Rulesï¼ˆæ ¸å¿ƒè§„åˆ™ï¼‰
- Learned Rulesï¼ˆå­¦ä¹ è§„åˆ™ï¼‰

æ”¯æŒè‡ªæˆ‘è¿›åŒ–ï¼Œæ¯æ¬¡ä»»åŠ¡æ‰§è¡Œåè‡ªåŠ¨å­¦ä¹ ã€‚
```

---

## æ€»ç»“

| Epic | Stories | é¢„ä¼°æ€»æ—¶é•¿ | ä¼˜å…ˆçº§ |
|------|---------|-----------|--------|
| Epic 1: è¿›åŒ–å¼•æ“ | 5 | 20h | P0 |
| Epic 2: Soul æ‰©å±• | 2 | 4h | P0 |
| Epic 3: Experience | 2 | 2h | P1 |
| Epic 4: Skills | 3 | 6h | P1 |
| Epic 5: è¿›åŒ–æ—¥å¿— | 2 | 4h | P1 |
| Epic 6: OpenCode | 1 | 2h | P1 |

**æ€»è®¡ï¼š15 Storiesï¼Œçº¦ 38hï¼ˆ5-6 å·¥ä½œæ—¥ï¼‰**

### å®æ–½é¡ºåº

```
Week 1:
â”œâ”€â”€ Epic 1: è¿›åŒ–å¼•æ“æ ¸å¿ƒ (P0)
â””â”€â”€ Epic 2: Soul ç³»ç»Ÿæ‰©å±• (P0)

Week 2:
â”œâ”€â”€ Epic 3: Experience ç›®å½• (P1)
â”œâ”€â”€ Epic 4: Skills æ¶æ„ (P1)
â”œâ”€â”€ Epic 5: è¿›åŒ–æ—¥å¿— (P1)
â””â”€â”€ Epic 6: OpenCode é›†æˆ (P1)
```
